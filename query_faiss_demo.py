from pathlib import Path
import json
from typing import List, Dict

import faiss
from sentence_transformers import SentenceTransformer

from openai import OpenAI
from dotenv import load_dotenv
import os

# ===== ç¯å¢ƒå˜é‡ & OpenAI å®¢æˆ·ç«¯ / Umgebungsvariablen & OpenAI-Client =====
load_dotenv()  # ä» .env è¯»å– OPENAI_API_KEY
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ===== è·¯å¾„é…ç½® / Pfad-Konfiguration =====
BASE_DIR = Path(r"D:\KI-Agent")

CHUNK_INPUT_PATH = BASE_DIR / "out" / "besser Chunk.jsonl"
FAISS_INDEX_PATH = BASE_DIR / "out" / "MM_SPO13_faiss.index"

MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
# å¿…é¡»ä¸æ„å»º FAISS ç´¢å¼•æ—¶ä½¿ç”¨çš„æ¨¡å‹ä¿æŒä¸€è‡´


# ===== è¾“å‡ºè¯­è¨€è§„åˆ™ / Sprachregeln =====
LANG_RULES = {
    "de": "Antworte ausschlieÃŸlich auf Deutsch.",
    "zh": "åªç”¨ä¸­æ–‡å›ç­”ï¼ˆæ¨¡å—/è¯¾ç¨‹åç§°ä¿ç•™å¾·è¯­åŸåï¼‰ã€‚",
    "en": "Answer only in English (keep German module/course names).",
    "all": "Gib die Antwort dreisprachig in genau dieser Reihenfolge aus: [DE], [ä¸­æ–‡], [EN]."
}

NO_CONTEXT_MSG = {
    "de": "In den bereitgestellten Unterlagen wurden keine passenden Informationen fÃ¼r diese Frage gefunden.",
    "zh": "åœ¨æä¾›çš„èµ„æ–™ä¸­æ²¡æœ‰æ‰¾åˆ°èƒ½ç›´æ¥å›ç­”è¿™ä¸ªé—®é¢˜çš„å†…å®¹ã€‚",
    "en": "No relevant information was found in the provided materials for this question.",
    "all": "[DE]\nIn den bereitgestellten Unterlagen wurden keine passenden Informationen fÃ¼r diese Frage gefunden.\n\n"
           "[ä¸­æ–‡]\nåœ¨æä¾›çš„èµ„æ–™ä¸­æ²¡æœ‰æ‰¾åˆ°èƒ½ç›´æ¥å›ç­”è¿™ä¸ªé—®é¢˜çš„å†…å®¹ã€‚\n\n"
           "[EN]\nNo relevant information was found in the provided materials for this question."
}


def load_chunks(path: Path) -> List[Dict]:
    """è¯»å– besser Chunk.jsonlï¼Œå¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ dictï¼ˆtext/page/doc/section ç­‰ï¼‰"""
    chunks: List[Dict] = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            chunks.append(json.loads(line))
    return chunks


def load_faiss_index(path: Path) -> faiss.Index:
    """ä»ç£ç›˜è¯»å–å·²ç»å»ºå¥½çš„ FAISS ç´¢å¼•"""
    return faiss.read_index(str(path))


def load_model(model_name: str) -> SentenceTransformer:
    """åŠ è½½ SentenceTransformer æ¨¡å‹ï¼ˆå’Œå»ºç´¢å¼•æ—¶åŒä¸€ä¸ªï¼‰"""
    return SentenceTransformer(model_name)


def search(
    query: str,
    model: SentenceTransformer,
    index: faiss.Index,
    chunks: List[Dict],
    top_k: int = 5,
):
    """
    - æŠŠé—®é¢˜ç¼–ç æˆå‘é‡
    - åœ¨ FAISS ä¸­æ£€ç´¢ top_k
    - ç”¨ä¸‹æ ‡å–å› chunks æ–‡æœ¬å’Œå…ƒä¿¡æ¯
    """
    query_emb = model.encode(
        [query],
        normalize_embeddings=True,
        convert_to_numpy=True,
    )

    D, I = index.search(query_emb, top_k)

    results = []
    for rank, idx in enumerate(I[0]):
        if idx == -1:
            continue
        ch = chunks[idx]
        results.append(
            {
                "rank": rank + 1,
                "score": float(D[0][rank]),
                "page": ch.get("page"),
                "section": ch.get("section"),
                "doc": ch.get("doc"),
                "text": ch.get("text", ""),
            }
        )
    return results


def build_context(results: List[Dict], max_chars: int = 3000) -> str:
    """
    æŠŠæ£€ç´¢åˆ°çš„ chunk æ‹¼æˆä¸€ä¸ªä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ˆå¸¦ä¸Š doc/page/sectionï¼Œæ–¹ä¾¿ LLM å¼•ç”¨ï¼‰
    """
    parts: List[str] = []
    length = 0

    for item in results:
        text = (item.get("text") or "").strip()
        if not text:
            continue

        header = f"[Dokument: {item.get('doc')} | Seite: {item.get('page')} | Abschnitt: {item.get('section')}]"
        block = f"{header}\n{text}"

        if length + len(block) > max_chars:
            break

        parts.append(block)
        length += len(block)

    return "\n\n".join(parts)


def translate_query_to_german(query: str) -> str:
    """
    ï¼ˆå¯é€‰ï¼‰æŠŠç”¨æˆ·é—®é¢˜ç¿»æˆå¾·è¯­ï¼Œç”¨äºæ£€ç´¢ï¼Œæé«˜å¬å›
    æ³¨æ„ï¼šåªè¿”å›ç¿»è¯‘æ–‡æœ¬ï¼Œä¸è¦è§£é‡Š
    """
    prompt = (
        "Ãœbersetze die folgende Frage ins Deutsche. "
        "Gib NUR die Ãœbersetzung aus, ohne ErklÃ¤rungen:\n\n"
        f"{query}"
    )
    resp = client.responses.create(
        model="gpt-4o-mini",
        input=prompt,
        max_output_tokens=120,
    )
    return (resp.output_text or "").strip()


def generate_answer_with_llm(question: str, context: str, output_lang: str) -> str:
    """
    ä½¿ç”¨ OpenAI LLMï¼Œæ ¹æ®â€œé—®é¢˜ + ä¸Šä¸‹æ–‡â€ç”Ÿæˆå›ç­”ï¼ˆè¯­è¨€å¯åˆ‡æ¢ï¼‰
    """
    output_lang = (output_lang or "de").lower()
    if output_lang not in LANG_RULES:
        output_lang = "de"

    if not context.strip():
        return NO_CONTEXT_MSG[output_lang]

    lang_rule = LANG_RULES[output_lang]

    prompt = f"""
Du bist ein Studienassistent. Du darfst NUR auf Basis des gegebenen Kontexts antworten.
Wenn der Kontext keine Antwort enthÃ¤lt, sage das klar (keine Erfindungen).

Wichtig (Ausgabe-Regeln):
- {lang_rule}
- Behalte Modul-/Kursnamen im Original (Deutsch).
- Antworte klar, prÃ¤zise; wenn sinnvoll mit Stichpunkten.
- Wenn du dir unsicher bist, sag es.

[Kontext]
{context}

[Frage]
{question}
""".strip()

    response = client.responses.create(
        model="gpt-4o-mini",
        input=prompt,
        max_output_tokens=512,
    )

    return (response.output_text or "").strip()


def answer_question(
    query: str,
    model: SentenceTransformer,
    index: faiss.Index,
    chunks: List[Dict],
    output_lang: str = "de",
    translate_for_retrieval: bool = False,
) -> Dict:
    """
    - (å¯é€‰) å…ˆç¿»è¯‘ä¸ºå¾·è¯­ç”¨äºæ£€ç´¢
    - search() æ‰¾ chunks
    - build_context()
    - LLM æŒ‰ output_lang è¾“å‡º
    """
    retrieval_query = query
    if translate_for_retrieval:
        try:
            retrieval_query = translate_query_to_german(query)
        except Exception:
            retrieval_query = query  # ç¿»è¯‘å¤±è´¥å°±é€€å›åŸå§‹é—®é¢˜

    hits = search(retrieval_query, model, index, chunks, top_k=5)
    context = build_context(hits, max_chars=3000)
    answer_text = generate_answer_with_llm(query, context, output_lang)

    return {
        "answer": answer_text,
        "hits": hits,
        "retrieval_query": retrieval_query,
    }


def main():
    print("ğŸ“¥ Lade Modell, Index und Chunks...")
    chunks = load_chunks(CHUNK_INPUT_PATH)
    print(f"   âœ Anzahl der Chunks: {len(chunks)}")

    index = load_faiss_index(FAISS_INDEX_PATH)
    print("   âœ FAISS-Index erfolgreich geladen")

    model = load_model(MODEL_NAME)
    print("   âœ Embedding-Modell erfolgreich geladen")

    print("âœ… Initialisierung abgeschlossen â€“ du kannst jetzt Fragen stellen!\n")

    mode = input("Modus wÃ¤hlen: 1 = nur Suche, 2 = Frage-Antwort mit LLM (Standard 1): ").strip() or "1"

    output_lang = input("Ausgabe-Sprache wÃ¤hlen (de/zh/en/all) [de]: ").strip().lower() or "de"
    if output_lang not in LANG_RULES:
        output_lang = "de"

    translate_for_retrieval = False  # é»˜è®¤å…³é—­ï¼šéœ€è¦å°± /retrieval on

    print("\nğŸ’¡ å¿«æ·æŒ‡ä»¤ï¼š")
    print("   /lang de|zh|en|all    â†’ åˆ‡æ¢è¾“å‡ºè¯­è¨€")
    print("   /retrieval on|off     â†’ æ˜¯å¦æŠŠé—®é¢˜å…ˆç¿»æˆå¾·è¯­å†æ£€ç´¢ï¼ˆæå‡å¬å›ï¼‰")
    print("   /help                 â†’ æŸ¥çœ‹æŒ‡ä»¤")
    print("   q                      â†’ é€€å‡º\n")

    while True:
        query = input("Bitte gib eine Frage ein (q zum Beenden): ").strip()
        if not query:
            continue
        if query.lower() == "q":
            print("ğŸ‘‹ Suche wird beendet.")
            break

        # ===== å‘½ä»¤å¤„ç† =====
        if query.startswith("/help"):
            print("\nCommands:")
            print("  /lang de|zh|en|all")
            print("  /retrieval on|off")
            print("  q (quit)\n")
            continue

        if query.startswith("/lang"):
            parts = query.split()
            if len(parts) >= 2 and parts[1].lower() in LANG_RULES:
                output_lang = parts[1].lower()
                print(f"âœ… è¾“å‡ºè¯­è¨€å·²åˆ‡æ¢ä¸º: {output_lang}\n")
            else:
                print("âŒ ç”¨æ³•ï¼š/lang de|zh|en|all\n")
            continue

        if query.startswith("/retrieval"):
            parts = query.split()
            if len(parts) >= 2 and parts[1].lower() in ["on", "off"]:
                translate_for_retrieval = (parts[1].lower() == "on")
                state = "ON" if translate_for_retrieval else "OFF"
                print(f"âœ… retrieval ç¿»è¯‘æ¨¡å¼: {state}\n")
            else:
                print("âŒ ç”¨æ³•ï¼š/retrieval on|off\n")
            continue

        print("\n" + "=" * 80)

        if mode == "2":
            result = answer_question(
                query=query,
                model=model,
                index=index,
                chunks=chunks,
                output_lang=output_lang,
                translate_for_retrieval=translate_for_retrieval,
            )

            print("ã€LLM Antwort / å›ç­” / Answerã€‘")
            print(result["answer"])

            # å¯é€‰ï¼šå±•ç¤ºæ£€ç´¢å®é™…ç”¨çš„ queryï¼ˆå¼€äº†ç¿»è¯‘æ—¶å¾ˆæœ‰ç”¨ï¼‰
            if translate_for_retrieval:
                print("\n[Retrieval-Query (DE)]")
                print(result["retrieval_query"])

            print("\nVerwendete Textausschnitte (Evidenz) / ä½¿ç”¨åˆ°çš„åŸæ–‡ç‰‡æ®µï¼ˆè¯æ®ï¼‰:")
            print("-" * 80)
            for h in result["hits"]:
                print(
                    f"[{h['rank']}] Ã„hnlichkeit: {h['score']:.4f} | "
                    f"Dokument: {h.get('doc')} | Seite: {h.get('page')} | Abschnitt: {h.get('section')}"
                )
                print(h["text"])
                print("-" * 80)
        else:
            hits = search(query, model, index, chunks, top_k=5)
            if not hits:
                print("ğŸ˜¶ Keine passenden Inhalte gefunden.")
            else:
                for h in hits:
                    print(
                        f"[{h['rank']}] Ã„hnlichkeit: {h['score']:.4f} | "
                        f"Dokument: {h.get('doc')} | Seite: {h.get('page')} | Abschnitt: {h.get('section')}"
                    )
                    print(h["text"])
                    print("-" * 80)

        print()


if __name__ == "__main__":
    main()
